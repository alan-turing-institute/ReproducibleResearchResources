# Reproducible Research Resources

This repository contains information to help you make your research reproducible.

This is a public repository and all resources are available under a [CC-BY licence](https://github.com/alan-turing-institute/ReproducibleResearchResources/blob/master/LICENSE). This means you're free to ***share*** them in any medium or format and to ***adapt*** them to your needs (even commercially) so long as you acknowledge Kirstie Whitaker, Martin O'Reilly and the Turing Reproducible Research contributing team.

## Table of contents

* [Announcement: Turing Reproducible Research Champions](#announcement-turing-reproducible-research-champions)
* [FAQ: Open Access](https://github.com/alan-turing-institute/ReproducibleResearchResources/blob/master/FAQ_OpenAccess.md)
<!---* [Call for Turing Reproducibile Research Champions](https://github.com/alan-turing-institute/ReproducibleResearchResources/blob/master/champions/call-for-champions.md) [Apply by Sunday 25th Feb 2018]--->
* [Reproducible Research Lunches](https://github.com/alan-turing-institute/ReproducibleResearchResources/blob/master/comms/reproducible-research-dropin-ann.md) [Every Friday at 12noon, usually in Ursula Franklin meeting room]

## Announcement: Turing Reproducible Research Champions

Thursday 24th May 2018

We are delighted to announce our three Turing Reproducible Research Champions: Theo Damoulas, Elena Kochkina and Terry Lyons.

Each of our Champions has proposed an example of their work that they want to ‚Äúlevel up‚Äù in terms of reproducibility - over the coming months, Kirstie Whitaker and the Research Engineering Group will build up a set of resources that can be used to reproduce the work in the selected papers.

We‚Äôre really excited to be working on such a range of projects, each of which presents a different challenge in terms of reproducibility.

Congratulations to all our Champions!

Regular updates about each of the Champions will be posted on their separate pages and on the #reproducible-research Slack channel.
Further details about the Champions programme can be found [here](https://github.com/alan-turing-institute/ReproducibleResearchResources/blob/master/champions/call-for-champions.md).

### Theo Damoulas
*Spatio-temporal Bayesian on-line changepoint detection with model selection*

In collaboration with Jeremias Knoblauch

We develop probabilistic algorithms for modelling and predicting non-stationary processes (such as e.g. air pollution, financial or other urban processes) across spatio-temporal domains.
This specific family of algorithms can be thought of as segmenting a complex dynamic process via more manageable local models.
Furthermore, we better exploit spatio-temporal correlation and retain multiple models and multiple potential segmentations in a formal probabilistic manner.

### Elena Kochkina
*Turing at SemEval-2017 Task 8: Sequential approach to rumour stance classification with branch-LSTM*

In collaboration with Maria Liakata and Isabelle Augenstein

In this paper we deal with rumour stance classification, the task of determining the attitude of the users discussing a rumour towards the truthfulness of the rumour.
Stance classification is considered to be an important step towards rumour verification, therefore performing well in this task is expected to be useful in debunking false rumours.
We propose a LSTM-based sequential model that, through modelling the conversational structure of tweets, outperforms other systems submitted to the SemEval-2017 Task 8.

### Terry Lyons
*A signature-based machine learning model for distinguishing bipolar disorder and borderline personality disorder*

In collaboration with Imanol Perez Arribas, Guy Goodwin, John Geddes and Kate Saunders

The diagnosis and provision of feedback for psychiatric disorders is hampered by the dependency on narrative recall and the difficulty of defining their persistence over time.
The shortcomings of current diagnostic approaches have motivated a ‚Äòbottom up‚Äô approach to monitoring using more objective data streams. However analysis of these data streams is very challenging.
This paper demonstrates that it is possible to place people on a spectrum using simple mood zoom information (daily scores for several emotions); the dimension reduction and restructuring achieved by signatures meant that even with the small samples available one was able to use second order information (the order of different events: anger before depression, ‚Ä¶) in addition to first order (intensity, longivity of depression) of events to give considerable classification power and allow the differing diagnoses of the communities participating in this trial to be well separated. 

Given the size of the trial, and the complex noisy nature of the data this was an excellent outcome clinically and from a data science point of view.
SpeciÔ¨Åcally, we sought, and succeeded to a good degree, to classify the diagnosis of participants on the basis of their evolving mood and predict their mood the following day.
The generality of the signature-based machine learning model allows these problems to be treated in similar and generic methodology that can be shared with other contexts where one is analysing complex multimodal data.



## Contributors

Thank you to all the members of the Turing Reproducible Research community.


<!-- ALL-CONTRIBUTORS-LIST:START - Do not remove or modify this section -->
| [<img src="https://avatars3.githubusercontent.com/u/3626306?s=400&v=4" width="100px;"/><br /><sub>Kirstie Whitaker</sub>](https://github.com/kirstiejane)<br /> :speech_balloon: [:book:](https://github.com/alan-turing-institute/ReproducibleResearchResources/commits?author=kirstiejane) ü§î :mag: :loudspeaker: | [<img src="https://avatars2.githubusercontent.com/u/21147592?s=460&v=4" width="100px;"/><br /><sub>Martin O'Reilly</sub>](https://github.com/martintoreilly)<br /> :speech_balloon: [üìñ](https://github.com/alan-turing-institute/ReproducibleResearchResources/commits?author=martintoreilly) ü§î :mag: :loudspeaker: |
| :---: | :---: |

<!-- ALL-CONTRIBUTORS-LIST:END -->

This project follows the [all-contributors][all-contributors] specification and this [emoji key][emojis] explains the different contributions.

[emojis]: https://github.com/kentcdodds/all-contributors#emoji-key
[all-contributors]: https://github.com/kentcdodds/all-contributors
